
from subprocess import call
import numpy as np
import pandas as pd
import scipy.stats
from time import localtime, strftime

import os

def mean_confidence_interval(data, confidence=0.95):
    a = 1.0 * np.array(data)
    n = len(a)
    m, se = np.mean(a), scipy.stats.sem(a)
    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)
    return m, m-h, m+h




rule ml_summarize:
    input: 
        json=expand("{outDir}/{phenIndex}/ml_eval.json",outDir=config["outDir"],phenIndex=range(config['phenRep'])),
        auc=expand("{outDir}/{phenIndex}/ml_eval.csv",outDir=config["outDir"],phenIndex=range(config['phenRep'])),
        cv=expand("{outDir}/{phenIndex}/mlOut.csv",outDir=config["outDir"],phenIndex=range(config['phenRep'])),
    output: 
        out_csv=expand("{outDir}/mlSum.csv",outDir=config["outDir"]),
        out_png=expand("{outDir}/mlSum.png",outDir=config["outDir"]),
    params:
        ml_eval_summarize=os.path.join('modules','mlSum','mlEvalSum.py'),
        ml_pre_rec_summarize=os.path.join('modules','mlSum','mlPreRecSum.py'),
        logNAME="Summarizing the performance of ML approach across simulations." + strftime("%Y-%m-%d.%H-%M-%S", localtime()),
        shellCallFile=os.path.join(config["outDir"],'MlBenchmarker.log')
    threads: 1
    run:
        jsonDir='/'.join(output.out_csv[0].split('/')[:-1])+'/jsonFiles.txt'
        txt=open(jsonDir,'w')
        for jsons in input.json:
            txt.write(jsons+'\n')
        txt.close()
        callString='%s %s --infile %s --out %s' %(config['python'],params.ml_eval_summarize,jsonDir,output.out_csv[0])
        call('echo "' + str(params.logNAME) + ':\n ' + callString + '\n" >> ' + params.shellCallFile, shell=True)
        call(callString, shell=True)
        #running the precison-recall auc scores
        csvDir='/'.join(output.out_png[0].split('/')[:-1])+'/csvFiles.txt'
        txt=open(csvDir,'w')
        for csvs in input.auc:
            txt.write(csvs+'\n')
        txt.close()
        callString='%s %s --infile %s --out %s' %(config['python'],params.ml_pre_rec_summarize,csvDir,output.out_png[0])
        call('echo "' + str(params.logNAME) + ':\n ' + callString + '\n" >> ' + params.shellCallFile, shell=True)
        call(callString, shell=True)
        #summarize results of cv scores across 10 replicates fo ml models only
        if config['method'] == 'ml':
          metrics_=pd.read_csv(input.cv[0][:-4]+'CV.csv',index_col=0).columns
          metrics={}
          for met_ in metrics_:
            metrics[met_]=[]
          for rep_ in input.cv:
            df=pd.read_csv(rep_[:-4]+'CV.csv')
            for met_ in metrics:
              metrics[met_].append(df[met_].tolist())
          cvSem={}
          for met_ in metrics:
            cvSem[met_]=mean_confidence_interval([item for sublist in metrics[met_] for item in sublist])
          cvDf=pd.DataFrame(cvSem)
          cvDf.to_csv(output.out_csv[0][:-4]+'cvSum.csv')


        

